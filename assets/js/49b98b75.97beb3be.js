"use strict";(self.webpackChunkCaptchaAgent=self.webpackChunkCaptchaAgent||[]).push([[7446],{6037:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>c,toc:()=>d});var o=t(5893),i=t(1151);const r={title:"Discord GEN",description:"It's your concern."},s=void 0,c={id:"examples/integration-with-discord-gen",title:"Discord GEN",description:"It's your concern.",source:"@site/docs/examples/05-integration-with-discord-gen.md",sourceDirName:"examples",slug:"/examples/integration-with-discord-gen",permalink:"/docs/examples/integration-with-discord-gen",draft:!1,unlisted:!1,editUrl:"https://github.com/CaptchaAgent/docs-source/tree/main/docs/examples/05-integration-with-discord-gen.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"Discord GEN",description:"It's your concern."},sidebar:"tutorialSidebar",previous:{title:"Self-Supervised Challenge",permalink:"/docs/examples/self-supervised-challenge"},next:{title:"Epic Games claimer",permalink:"/docs/examples/integration-with-epic-claimer"}},a={},d=[{value:"Introduction",id:"introduction",level:2}];function l(e){const n={code:"code",h2:"h2",p:"p",...(0,i.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,o.jsx)(n.p,{children:"CaptchAgent enables you to run model inference tasks in a locally based environment. That is, you can perform ultra-high concurrency computer vision tasks (e.g., image classification, object detection, image segmentation) and you can process hundreds of images in seconds."}),"\n",(0,o.jsx)(n.p,{children:"For example, you can implement your own CAPTCHA-specific decoder without relying on any third-party solver service. So you don't need to share a queue with anyone, you don't need to wait tens or even hundreds of seconds for a queue, all processing is instantly responsive."}),"\n",(0,o.jsxs)(n.p,{children:["In addition, we packaged all models in ModelHub into ONNX format. At the same time, downstream tasks run inference tasks with ",(0,o.jsx)(n.code,{children:"onnxruntime"}),", meaning you can run AI models even if you don't have a GPU in your runtime environment."]})]})}function u(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},1151:(e,n,t)=>{t.d(n,{Z:()=>c,a:()=>s});var o=t(7294);const i={},r=o.createContext(i);function s(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);