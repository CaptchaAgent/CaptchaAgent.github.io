"use strict";(self.webpackChunkCaptchaAgent=self.webpackChunkCaptchaAgent||[]).push([[5144],{3149:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>c,toc:()=>d});var o=t(5893),i=t(1151);const s={title:"Discord GEN",description:"It's your concern."},r=void 0,c={id:"examples/integration-with-discord-gen",title:"Discord GEN",description:"It's your concern.",source:"@site/i18n/zh-Hans/docusaurus-plugin-content-docs/current/examples/05-integration-with-discord-gen.md",sourceDirName:"examples",slug:"/examples/integration-with-discord-gen",permalink:"/zh-Hans/docs/examples/integration-with-discord-gen",draft:!1,unlisted:!1,editUrl:"https://github.com/CaptchaAgent/docs-source/tree/main/docs/examples/05-integration-with-discord-gen.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"Discord GEN",description:"It's your concern."},sidebar:"tutorialSidebar",previous:{title:"Self-Supervised Challenge",permalink:"/zh-Hans/docs/examples/self-supervised-challenge"},next:{title:"Epic Games claimer",permalink:"/zh-Hans/docs/examples/integration-with-epic-claimer"}},a={},d=[{value:"Introduction",id:"introduction",level:2}];function l(e){const n={code:"code",h2:"h2",p:"p",...(0,i.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,o.jsx)(n.p,{children:"CaptchaAgent allows you to run model inference tasks locally. That means you can process hundreds of images in seconds while performing ultra-concurrent computer vision tasks (such as image classification, object detection, and image segmentation)."}),"\n",(0,o.jsx)(n.p,{children:"For instance, you don't need to use any outside solver services to implement your own CAPTCHA-specific solver. This eliminates the need for you to wait tens or even hundreds of seconds in line or share queues with other people. Everything is processed in real time here."}),"\n",(0,o.jsxs)(n.p,{children:["In addition, we converted all ModelHub models to ONNX format. At the same time, downstream tasks use ",(0,o.jsx)(n.code,{children:"onnxruntime"})," to run inference tasks, allowing you to run AI models even if your runtime environment lacks a GPU."]})]})}function u(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},1151:(e,n,t)=>{t.d(n,{Z:()=>c,a:()=>r});var o=t(7294);const i={},s=o.createContext(i);function r(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);